# üì¶ DataClean Co. ‚Äî Gabarito do Desafio (M√≥dulo 4: Tratando Dados)
# Autor: Rocketseat Python (estilo das aulas)
# Objetivo: Demonstrar, passo a passo, como tratar dados (nulos, duplicatas, outliers),
#           normalizar, codificar vari√°veis categ√≥ricas, trabalhar com datas e gerar visualiza√ß√µes.
#
# Observa√ß√£o importante:
# - Este arquivo foi escrito em formato did√°tico, com se√ß√µes numeradas e coment√°rios,
#   seguindo o mesmo esp√≠rito do gabarito "analise_vendas_techstore.py".
# - Para executar localmente, deixe o arquivo "dados_clientes.csv" na mesma pasta deste script.

# ---
# ## 1. Importa√ß√£o das bibliotecas
# pandas para manipula√ß√£o tabular, numpy para c√°lculos num√©ricos e matplotlib para gr√°ficos.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Garantir que os gr√°ficos abram em janelas separadas quando usado em alguns ambientes:
# (Em notebooks n√£o √© necess√°rio.)
# plt.switch_backend("agg")  # Descomente caso precise salvar sem interface gr√°fica

# ---
# ## 2. Leitura do arquivo CSV
# Lemos o CSV gerado para o desafio. Ele cont√©m intencionalmente nulos, duplicatas,
# formata√ß√µes diferentes de data e alguns outliers realistas.
print("== 2) Leitura do CSV ==")
df = pd.read_csv("dados_clientes.csv")
print("5 primeiras linhas:")
print(df.head(), "\n")

# ---
# ## 3. Explora√ß√£o inicial dos dados (overview)
print("== 3) Overview ==")
print("Informa√ß√µes gerais:")
print(df.info(), "\n")
print("Formato (linhas, colunas):", df.shape)
print("Tipos de dados:\n", df.dtypes, "\n")
print("Estat√≠sticas descritivas (num√©ricas):\n", df.describe(numeric_only=True), "\n")

# ---
# ## 4. Tratamento de valores ausentes
# Estrat√©gia did√°tica (simples e transparente):
# - 'idade': preencher com a mediana (evita distor√ß√µes por outliers).
# - 'renda_anual': preencher com a mediana.
# - 'valor_compra': preencher com a mediana por 'categoria_produto' (contextual).
# - 'data_compra': manter nulos por ora (ser√£o tratados ao converter datas).
print("== 4) Valores ausentes ==")
print("Contagem de nulos antes:\n", df.isna().sum(), "\n")

idade_mediana = df['idade'].median(skipna=True)
renda_mediana = df['renda_anual'].median(skipna=True)

df['idade'] = df['idade'].fillna(idade_mediana)
df['renda_anual'] = df['renda_anual'].fillna(renda_mediana)

# Para valor_compra, usar mediana por categoria (quando poss√≠vel)
medianas_por_cat = df.groupby('categoria_produto')['valor_compra'].median()
def preencher_valor_compra(row):
    if pd.isna(row['valor_compra']):
        cat = row['categoria_produto']
        med_cat = medianas_por_cat.get(cat, df['valor_compra'].median())
        return med_cat
    return row['valor_compra']

df['valor_compra'] = df.apply(preencher_valor_compra, axis=1)

print("Contagem de nulos depois:\n", df.isna().sum(), "\n")

# ---
# ## 5. Tratamento de duplicatas
# Duas abordagens comuns:
# - Dropar duplicatas completas (linhas id√™nticas).
# - Ou dropar duplicatas por um subconjunto de colunas-chave.
# Aqui, faremos primeiro o drop de duplicatas completas, depois avaliamos caso a caso.
print("== 5) Duplicatas ==")
duplicatas_antes = df.duplicated().sum()
print("Duplicatas (linhas completamente id√™nticas) antes:", duplicatas_antes)

df = df.drop_duplicates(keep='first')
duplicatas_depois = df.duplicated().sum()
print("Duplicatas depois:", duplicatas_depois, "\n")

# Observa√ß√£o: se necess√°rio, poder√≠amos usar um subset, por exemplo:
# df = df.drop_duplicates(subset=['id_cliente', 'data_compra', 'categoria_produto', 'valor_compra'], keep='first')

# ---
# ## 6. Convers√£o e engenharia de datas
# As datas vieram em formatos mistos. Vamos padronizar para datetime,
# aceitar erros (coercion) e criar colunas derivadas (ano, mes, dia_semana).
print("== 6) Datas ==")
# Tentar dia-primeiro e tamb√©m outros formatos em sequ√™ncia:
def parse_data_seguro(s):
    # Tenta ISO e dia-primeiro
    dt = pd.to_datetime(s, errors='coerce', dayfirst=True)
    if pd.isna(dt):
        dt = pd.to_datetime(s, errors='coerce')  # segunda tentativa (ISO)
    return dt

df['data_compra'] = df['data_compra'].apply(parse_data_seguro)

print("Nulos em data_compra ap√≥s parse:", df['data_compra'].isna().sum())

# Criar colunas derivadas
df['ano'] = df['data_compra'].dt.year
df['mes'] = df['data_compra'].dt.month
df['dia_semana'] = df['data_compra'].dt.day_name(locale='pt_BR') if hasattr(pd.Series.dt, "day_name") else df['data_compra'].dt.dayofweek

print("Preview de colunas de data:\n", df[['data_compra', 'ano', 'mes']].head(), "\n")

# ---
# ## 7. An√°lise e tratamento de outliers (IQR/Boxplot rule)
# Vamos aplicar a regra do IQR nas colunas num√©ricas-chave: 'renda_anual' e 'valor_compra'.
print("== 7) Outliers (IQR) ==")
def winsorizar_iqr(serie):
    q1 = serie.quantile(0.25)
    q3 = serie.quantile(0.75)
    iqr = q3 - q1
    lim_inf = q1 - 1.5 * iqr
    lim_sup = q3 + 1.5 * iqr
    # Em vez de remover, faremos "capping" (winsoriza√ß√£o) para manter o tamanho da amostra.
    return serie.clip(lower=lim_inf, upper=lim_sup), (lim_inf, lim_sup)

df['renda_anual'], (renda_inf, renda_sup) = winsorizar_iqr(df['renda_anual'])
df['valor_compra'], (compra_inf, compra_sup) = winsorizar_iqr(df['valor_compra'])

print(f"Limites renda_anual: [{renda_inf:.2f}, {renda_sup:.2f}]")
print(f"Limites valor_compra: [{compra_inf:.2f}, {compra_sup:.2f}]\n")

# ---
# ## 8. Normaliza√ß√£o (escala 0-1) e Encoding de categ√≥ricas
# - Normaliza√ß√£o Min-Max em 'renda_anual' e 'valor_compra' (novas colunas *_norm).
# - One-Hot Encoding para 'genero' e 'categoria_produto' (novas colunas dummy_*).
print("== 8) Normaliza√ß√£o e Encoding ==")
def minmax(col):
    cmin, cmax = col.min(), col.max()
    return (col - cmin) / (cmax - cmin) if cmax != cmin else col*0

df['renda_anual_norm'] = minmax(df['renda_anual'])
df['valor_compra_norm'] = minmax(df['valor_compra'])

dummies = pd.get_dummies(df[['genero', 'categoria_produto']], prefix=['genero', 'cat'], dtype=int)
df = pd.concat([df, dummies], axis=1)

print("Colunas adicionadas (normaliza√ß√£o e dummies) criadas com sucesso.\n")

# ---
# ## 9. Visualiza√ß√µes (matplotlib puro)
# Observa√ß√£o: cada gr√°fico tem sua pr√≥pria figura. N√£o definimos cores manualmente.
print("== 9) Gr√°ficos ==")
# 9.1 Histograma da renda anual
plt.figure(figsize=(8,5))
plt.hist(df['renda_anual'].dropna(), bins=10)
plt.title('Distribui√ß√£o da Renda Anual')
plt.xlabel('Renda Anual (R$)')
plt.ylabel('Frequ√™ncia')
plt.tight_layout()
plt.show()

# 9.2 Boxplot do valor_compra por categoria_produto
# Preparar os dados por categoria
cats = df['categoria_produto'].dropna().unique()
data_by_cat = [df.loc[df['categoria_produto'] == c, 'valor_compra'].dropna().values for c in cats]

plt.figure(figsize=(8,5))
plt.boxplot(data_by_cat, labels=cats, showmeans=True)
plt.title('Valor de Compra por Categoria')
plt.xlabel('Categoria do Produto')
plt.ylabel('Valor da Compra (R$)')
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

# 9.3 Scatterplot idade vs valor_compra
plt.figure(figsize=(8,5))
plt.scatter(df['idade'], df['valor_compra'])
plt.title('Idade vs Valor da Compra')
plt.xlabel('Idade')
plt.ylabel('Valor da Compra (R$)')
plt.tight_layout()
plt.show()

# 9.4 "Heatmap" simples de correla√ß√£o (com imshow)
corr = df.select_dtypes(include=[np.number]).corr(numeric_only=True)
plt.figure(figsize=(7,6))
im = plt.imshow(corr, aspect='auto')
plt.title('Matriz de Correla√ß√£o (num√©ricas)')
plt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha='right')
plt.yticks(range(len(corr.index)), corr.index)
plt.colorbar(im, fraction=0.046, pad=0.04)
plt.tight_layout()
plt.show()

# ---
# ## 10. Exporta√ß√£o do dataset limpo
print("== 10) Exporta√ß√£o ==")
saida = "dados_clientes_limpos.csv"
df.to_csv(saida, index=False, encoding="utf-8")
print(f"Arquivo '{saida}' exportado com sucesso!")

# ---
# ## 11. Conclus√£o
# Neste gabarito, aplicamos o pipeline essencial de tratamento de dados:
# - overview e diagn√≥stico
# - preenchimento de valores ausentes
# - deduplica√ß√£o
# - padroniza√ß√£o e engenharia de datas
# - detec√ß√£o e capping de outliers via IQR
# - normaliza√ß√£o e encoding de categ√≥ricas
# - visualiza√ß√µes para explorar distribui√ß√£o, rela√ß√£o e correla√ß√£o
# - exporta√ß√£o do dataset limpo para uso posterior
#
# Sugest√µes de estudo:
# - Experimente trocar a mediana por m√©dia ou KNN-Imputer para nulos.
# - Compare remover outliers vs. winsorizar e observe impacto nas m√©tricas.
# - Teste padroniza√ß√£o (z-score) no lugar de min-max e compare resultados.
# - Ajuste a granularidade temporal (por m√™s/semana) e crie novas features.
print("Pipeline finalizado com sucesso. üöÄ")
